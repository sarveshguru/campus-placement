# Resume_Screening
Resume Screening Using Machine Learning 

Problem Statement:

-	Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates.
-	Hiring the right talent is a challenge for all businesses. This challenge is magnified by the high volume of applicants if the business is labour-intensive, growing, and facing high attrition rates.
-	IT departments are short of growing markets. In a typical service organization, professionals with a variety of technical skills and business domain expertise are hired and assigned to projects to resolve customer issues. This task of selecting the best talent among many others is known as Resume Screening.
-	Typically, large companies do not have enough time to open each CV, so they use machine learning algorithms for the Resume Screening task.


Why do we need Resume Screening?

-	For each recruitment, companies take out the resume, referrals and go through them manually.
-	Companies often received thousands of resumes for every job posting.
-	When companies collect resumes then they categorize those resumes according to their requirements and then they send the collected resumes to the Hiring Teams.
-	It becomes very difficult for the hiring teams to read the resume and select the resume according to the requirement, there is no problem if there are one or two resumes but it is very difficult to go through 1000’s resumes and select the best one.
-	To solve this problem, we will screen the resume using machine learning and NLP using Python Programming Language so that we can complete days of work in few minutes.


Essence of Resume Screening:

-	It is the process of determining whether a candidate is qualified for a role based his or her education, experience, and other information captured on their resume.
-	It is a crucial yet challenging part of the hiring process.
-	On average, a recruiter spends 23 hours screening resumes for a single hire.
-	Even with automated processes, it is still the most time-consuming part of recruiting.


1.	Data Collection:
•	Gather comprehensive resume data from multiple sources.

2.	Exploratory Data Analysis (EDA):
•	Conduct exploratory analysis to understand the patterns within the data and make observation on the basis to features.

3.	Data Preprocessing:
•	Clean, preprocess, and integrate data from various sources to ensure consistency and accuracy.

4.	Model Selection and Training:
•	Select appropriate machine learning algorithms, such as KNeighboursClassifier and One vs Rest method for predicting best fit resume outcomes and understanding influential factors.
•	Train and validate models using historical resume data.

5.	Pattern Identification and Identification:
•	Analyse model results to identify significant trends, patterns, and key factors contributing to successful resumes.
•	Interpret the importance of various features in the prediction process.

6.	Visualization and Reporting:
•	Create informative visualizations, including pie chart, count plot, to visually represent the relationships between variables.
•	Generate comprehensive reports that present the findings in a clear and understandable manner.
•	Compare the performance of different machine learning algorithms to determine the most accurate and reliable model for predicting best resume.

7.	Predictive Analysis:
•	Deploy the trained models to predict best fit resume which is suitable for their work. It helps many companies to save time, money and hard work.

8.	Comparative Analysis:
•	Compare the performance of different machine learning algorithms to determine the most accurate and reliable model for predicting best resume.

9.	Future Recommendation:
•	Designed to meet the needs of recruiters that current technology cannot solve, a new class of recruiting technology called AI for recruitment has arrived.
•	Industry experts predict this type of automation technology will transform the recruiting function.

Modules & Library Description:

	Modules
o	KNN: - It is a supervised technique, used for classification. “K” in the KNN represents the number of nearest neighbours used to classify or predict in case of continuous variable.

 

o	NLP: - NLP is a field in machine learning with the ability of a computer to understand, analyse, manipulate, and potentially generate human language.



	Libraries
o	NumPy: - NumPy is one of the fundamental packages for python providing support for large multidimensional arrays and metrices.

o	Pandas: - It is and open-source python library. Pandas enable the provision of easy data structure and quicker data analysis for python. For operations like data analysis and modelling.

o	Matplotlib: - This open-source library in python is widely used for publication of quality figures in a variety of hard copy formats and interactive environments across platforms. You can design charts, graphs, pie charts, scatterplots, histograms, error charts, etc. with just a few lines of code.

o	Seaborn: - When it comes to visualisation of statistical models like heat maps, seaborn is among the reliable sources. This python library is derived from matplotlib and closely integrated with pandas data structures.

o	SciPy: - This is yet another open-source software used for scientific computing in python. Apart from that, SciPy is also used for data computation, productivity, and high-performance computing and quality assurance.

o	Scikit-Learn: - It is a free software machine learning library for the python programming language and can be effectively used for a variety of applications which include classification, regression, clustering, model selection, naïve bayes’, grade boosting, k-means and preprocessing.

o	NLTK: - Natural Language Toolkit or NLTK is said to be one among the popular python NLP library. It contains a set of preprocessing libraries that provide processing solutions for numerical and symbolic language processing in English only.


Expected Outcomes:

•	Trained machine learning models capable of predicting resume outcomes for companies.
•	Insights into significant trends, patterns, and influential factors affecting resume.
•	Informative visualizations and reports that present findings in a clear and understandable manner.
•	Recommendations for students to enhance their placement prospects and institutions to optimize their placement strategies.

Conclusion:

     The proposed system is currently under implementation and we are working on making as accurate as possible. This system will definitely aid the recruiters to filter out the most prospective candidates based on their resumes for further rounds in the hiring process. It will ease the burden of the recruiters and they will not have to manually view each and every resume of the large pool of candidates.
